{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f8cd76b",
   "metadata": {},
   "source": [
    "## III. Baseline #2: Nearest neighbours questions\n",
    "\n",
    "We apply the embeddings to questions title and feed them into a ANN model that will help us retrieve the nearest, say, 100 questions. With a simple ranking on users associated to those questions, we might obtain a decent baseline.\n",
    "\n",
    "We will use [Spotify ANNOY](https://github.com/spotify/annoy) model for fast indexing and retrieval of candidates questions. On benchmarks, ANNOY is faster than Facebook FAISS, and the high-dimensionality of our embeddings forbid us from using KDTree, prone to the curse of dimensionality.\n",
    "\n",
    "Pros of the model:\n",
    "- Simple to implement\n",
    "- Fast in production and adapted to batch, precompute inference settings\n",
    "- Intuitive results\n",
    "- Possibility to build a more complex ranking system afterwards\n",
    "\n",
    "Cons:\n",
    "- Two models instead of one\n",
    "- ANN is an Inductive model, we need to rebuild the indexing for each new entry, so it might not be ideal in a real-time setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4410869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vincentmaladiere/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "from src.data import load_data, split_questions, save_results_csv, DATA_PATH\n",
    "from src.embedder import BertEmbedder\n",
    "from src.score import precision_k, recall_k\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49706f0",
   "metadata": {},
   "source": [
    "Set `USE_PRECOMPUTE` to `True` once you have computed embeddings. This will result in a significant speed-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b01aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PRECOMPUTE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11f0896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_answers.shape: (95709, 6)\n",
      "df_questions.shape: (100000, 6)\n",
      "df_users.shape: (138698, 12)\n"
     ]
    }
   ],
   "source": [
    "df_answers, df_questions, df_users = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ee268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_train.shape: (65036, 8)\n",
      "Q_val.shape: (5000, 8)\n",
      "Q_test.shape: (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "Q_train, Q_val, Q_test = split_questions(df_questions, df_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99451822",
   "metadata": {},
   "source": [
    "We begin by computing embeddings of both train and validation questions title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8234b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_questions_embeddings(df_questions, embedder, file_name):\n",
    "    results = []\n",
    "    for (question_id, title) in tqdm(df_questions[[\"question_id\", \"title\"]].values):\n",
    "        embeddings = embedder.get_embeddings(title)\n",
    "        results.append({\"question_id\": question_id, \"title\": title, \"embeddings\": embeddings})\n",
    "    file_path = os.path.join(DATA_PATH, file_name)\n",
    "    df_q_embeddings = pd.DataFrame(results)\n",
    "    df_q_embeddings.to_pickle(file_path)\n",
    "    print(f\"{file_name} written\")\n",
    "    return df_q_embeddings\n",
    "\n",
    "def load_questions_embeddings(file_name):\n",
    "    file_path = os.path.join(DATA_PATH, \"intermediary\", file_name)\n",
    "    return pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3115b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedder = BertEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3889937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"q_embeddings.pkl\"\n",
    "if USE_PRECOMPUTE:\n",
    "    df_q_embeddings = load_questions_embeddings(file_name)\n",
    "else:\n",
    "    Q_train_val = pd.concat([Q_train, Q_val])\n",
    "    df_q_embeddings = compute_questions_embeddings(Q_train_val, embedder, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c070c7",
   "metadata": {},
   "source": [
    "Quick demo using the first question indexed (index 0), we query the 10 neareast questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a709d8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c202dd322e44fb6b9dc47ec2057177f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = AnnoyIndex(768, \"angular\")\n",
    "embeddings = df_q_embeddings.embeddings.values\n",
    "for idx, v in tqdm(enumerate(embeddings), total=len(embeddings)):\n",
    "    ann.add_item(idx, v)\n",
    "ann.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd384c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>title</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>63142034</td>\n",
       "      <td>How to create an automation for tplink pharos ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>63051247</td>\n",
       "      <td>selenium cannot import name webdriver in ubuntu</td>\n",
       "      <td>0.337811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15578</th>\n",
       "      <td>63695568</td>\n",
       "      <td>Is there any embedded database for Node.js tha...</td>\n",
       "      <td>0.347284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32458</th>\n",
       "      <td>63849070</td>\n",
       "      <td>Authentication Exception when trying to connec...</td>\n",
       "      <td>0.367351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39417</th>\n",
       "      <td>61494103</td>\n",
       "      <td>Neovim plugin Fugitive isn't using the ssh key...</td>\n",
       "      <td>0.368468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52724</th>\n",
       "      <td>63230711</td>\n",
       "      <td>Configuration domain name on nginx on linux?</td>\n",
       "      <td>0.369126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54445</th>\n",
       "      <td>63841827</td>\n",
       "      <td>How do I use synology domain name for azure</td>\n",
       "      <td>0.371456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55446</th>\n",
       "      <td>60364031</td>\n",
       "      <td>git username visible to nginx</td>\n",
       "      <td>0.372364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84514</th>\n",
       "      <td>62677039</td>\n",
       "      <td>Displaying data from mySQL database to vue.js ...</td>\n",
       "      <td>0.372692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95698</th>\n",
       "      <td>60544448</td>\n",
       "      <td>selenium with firefox close tab by javascript ...</td>\n",
       "      <td>0.373452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id                                              title  \\\n",
       "2171      63142034  How to create an automation for tplink pharos ...   \n",
       "4682      63051247    selenium cannot import name webdriver in ubuntu   \n",
       "15578     63695568  Is there any embedded database for Node.js tha...   \n",
       "32458     63849070  Authentication Exception when trying to connec...   \n",
       "39417     61494103  Neovim plugin Fugitive isn't using the ssh key...   \n",
       "52724     63230711       Configuration domain name on nginx on linux?   \n",
       "54445     63841827        How do I use synology domain name for azure   \n",
       "55446     60364031                      git username visible to nginx   \n",
       "84514     62677039  Displaying data from mySQL database to vue.js ...   \n",
       "95698     60544448  selenium with firefox close tab by javascript ...   \n",
       "\n",
       "       distances  \n",
       "2171    0.000000  \n",
       "4682    0.337811  \n",
       "15578   0.347284  \n",
       "32458   0.367351  \n",
       "39417   0.368468  \n",
       "52724   0.369126  \n",
       "54445   0.371456  \n",
       "55446   0.372364  \n",
       "84514   0.372692  \n",
       "95698   0.373452  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs, distances = ann.get_nns_by_item(0, 10, include_distances=True)\n",
    "question_ids = df_q_embeddings.iloc[idxs].question_id\n",
    "df_results = df_questions.loc[df_questions.question_id.isin(question_ids)][[\"question_id\", \"title\"]]\n",
    "df_results[\"distances\"] = distances\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54bdbc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['How to create an automation for tplink pharos cpe520 using xpath with selenium and python for log in?',\n",
       "       'selenium cannot import name webdriver in ubuntu',\n",
       "       'Is there any embedded database for Node.js that allows to use mongoose driver API?',\n",
       "       'Authentication Exception when trying to connect to Amazon keyspace using .net core and cassandra csharp driver from linux',\n",
       "       \"Neovim plugin Fugitive isn't using the ssh key agent, so I can't Gpush/Git push\",\n",
       "       'Configuration domain name on nginx on linux?',\n",
       "       'How do I use synology domain name for azure',\n",
       "       'git username visible to nginx',\n",
       "       'Displaying data from mySQL database to vue.js front end using PHP',\n",
       "       'selenium with firefox close tab by javascript but SetTimeout() not ok'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.title.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c73e7",
   "metadata": {},
   "source": [
    "In the results above, we have returned the 9 closest titles to the first one (notice the increasing distances between the first row and the rest). There is room for improvement in those results: we find some similarity based on API, proxy and selenium but questions linked to ssh seems to be a bit far-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0d72b",
   "metadata": {},
   "source": [
    "We now define the dataset that our model will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6503ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset:\n",
    "    question_ids_to_predict: list[int]\n",
    "    embeddings: list\n",
    "    questions_idxs_mapping: pd.DataFrame\n",
    "    df_answers: pd.DataFrame\n",
    "    df_users: pd.DataFrame\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_ids_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff06276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(\n",
    "    question_ids_to_predict=Q_val.question_id.values,\n",
    "    embeddings=df_q_embeddings.embeddings.tolist(),\n",
    "    questions_idxs_mapping=pd.concat([Q_train, Q_val]),\n",
    "    df_answers=df_answers,\n",
    "    df_users=df_users,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70a55f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Ranker:    \n",
    "    \n",
    "    def predict_users(self, ds, n_top_users=20, k_nearest_questions=40):\n",
    "        self.ann = self.build_ann(ds)\n",
    "        results = []\n",
    "        print(\" # [ANN_Ranker] Make users predictions\")\n",
    "        for idx, question_id in enumerate(tqdm(ds.question_ids_to_predict, total=len(ds))):\n",
    "            question_ids = self.get_nearest_questions(idx, ds, k_nearest_questions)\n",
    "            top_user_ids = self.get_top_users(question_ids, ds, n_top=20)\n",
    "            results.append(np.hstack([question_id, top_user_ids]))\n",
    "        save_results_csv(\"baseline_2_results.csv\", results)\n",
    "    \n",
    "    def build_ann(self, ds, distance=\"angular\", size=768):\n",
    "        print(\" # [ANN_Ranker] Build ANN\")\n",
    "        ann = AnnoyIndex(size, distance)\n",
    "        for idx, v in tqdm(enumerate(ds.embeddings), total=len(ds.embeddings)):\n",
    "            ann.add_item(idx, v)\n",
    "        ann.build(10)\n",
    "        return ann\n",
    "\n",
    "    def get_nearest_questions(self, idx, ds, k_nearest_questions):\n",
    "        idxs = ann.get_nns_by_item(idx, k_nearest_questions)\n",
    "        idxs = np.array(idxs)\n",
    "        question_ids = ds.questions_idxs_mapping.iloc[idxs].question_id.values\n",
    "        return question_ids\n",
    "\n",
    "    def get_top_users(self, question_ids, ds, n_top=20):\n",
    "        df_answers_nn = ds.df_answers.loc[ds.df_answers.question_id.isin(question_ids)]\n",
    "        df_top_users = df_answers_nn.groupby(\"user_id\").score.sum().reset_index()\n",
    "        df_top_users = df_top_users.merge(\n",
    "            ds.df_users[[\"id\", \"reputation\"]], left_on=\"user_id\", right_on=\"id\", how=\"left\"\n",
    "        )\n",
    "        df_top_users.sort_values([\"score\", \"reputation\"], ascending=[False, False], inplace=True)\n",
    "        return df_top_users.user_id[:n_top].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67a07966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # [ANN_Ranker] Build ANN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c298d22bc514c93948a88d1ed87178f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # [ANN_Ranker] Make users predictions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86db6734ee374cb4b82c1fd2ba890b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/results/baseline_2_results.csv written\n"
     ]
    }
   ],
   "source": [
    "ann_ranker = ANN_Ranker()\n",
    "ann_ranker.predict_users(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b7593fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1_id</th>\n",
       "      <th>user2_id</th>\n",
       "      <th>user3_id</th>\n",
       "      <th>user4_id</th>\n",
       "      <th>user5_id</th>\n",
       "      <th>user6_id</th>\n",
       "      <th>user7_id</th>\n",
       "      <th>user8_id</th>\n",
       "      <th>user9_id</th>\n",
       "      <th>user10_id</th>\n",
       "      <th>user11_id</th>\n",
       "      <th>user12_id</th>\n",
       "      <th>user13_id</th>\n",
       "      <th>user14_id</th>\n",
       "      <th>user15_id</th>\n",
       "      <th>user16_id</th>\n",
       "      <th>user17_id</th>\n",
       "      <th>user18_id</th>\n",
       "      <th>user19_id</th>\n",
       "      <th>user20_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61821197</th>\n",
       "      <td>6309</td>\n",
       "      <td>1658906</td>\n",
       "      <td>8813644</td>\n",
       "      <td>12821415</td>\n",
       "      <td>11061080</td>\n",
       "      <td>5531620</td>\n",
       "      <td>10914284</td>\n",
       "      <td>3120345</td>\n",
       "      <td>10112092</td>\n",
       "      <td>6105207.0</td>\n",
       "      <td>1755598.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60874696</th>\n",
       "      <td>4238408</td>\n",
       "      <td>4665755</td>\n",
       "      <td>440558</td>\n",
       "      <td>532312</td>\n",
       "      <td>6464308</td>\n",
       "      <td>5483526</td>\n",
       "      <td>1283345</td>\n",
       "      <td>3113485</td>\n",
       "      <td>2203038</td>\n",
       "      <td>2449301.0</td>\n",
       "      <td>12890198.0</td>\n",
       "      <td>11237191.0</td>\n",
       "      <td>11309701.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64374269</th>\n",
       "      <td>12323248</td>\n",
       "      <td>3219613</td>\n",
       "      <td>7299782</td>\n",
       "      <td>4785185</td>\n",
       "      <td>11657533</td>\n",
       "      <td>12000053</td>\n",
       "      <td>7549483</td>\n",
       "      <td>10917379</td>\n",
       "      <td>7878602</td>\n",
       "      <td>4338278.0</td>\n",
       "      <td>10676716.0</td>\n",
       "      <td>13658399.0</td>\n",
       "      <td>7873768.0</td>\n",
       "      <td>13395142.0</td>\n",
       "      <td>3607430.0</td>\n",
       "      <td>14075054.0</td>\n",
       "      <td>9240550.0</td>\n",
       "      <td>10260243.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user1_id  user2_id  user3_id  user4_id  user5_id  user6_id  \\\n",
       "question_id                                                               \n",
       "61821197         6309   1658906   8813644  12821415  11061080   5531620   \n",
       "60874696      4238408   4665755    440558    532312   6464308   5483526   \n",
       "64374269     12323248   3219613   7299782   4785185  11657533  12000053   \n",
       "\n",
       "             user7_id  user8_id  user9_id  user10_id   user11_id   user12_id  \\\n",
       "question_id                                                                    \n",
       "61821197     10914284   3120345  10112092  6105207.0   1755598.0         NaN   \n",
       "60874696      1283345   3113485   2203038  2449301.0  12890198.0  11237191.0   \n",
       "64374269      7549483  10917379   7878602  4338278.0  10676716.0  13658399.0   \n",
       "\n",
       "              user13_id   user14_id  user15_id   user16_id  user17_id  \\\n",
       "question_id                                                             \n",
       "61821197            NaN         NaN        NaN         NaN        NaN   \n",
       "60874696     11309701.0         NaN        NaN         NaN        NaN   \n",
       "64374269      7873768.0  13395142.0  3607430.0  14075054.0  9240550.0   \n",
       "\n",
       "              user18_id  user19_id  user20_id  \n",
       "question_id                                    \n",
       "61821197            NaN        NaN        NaN  \n",
       "60874696            NaN        NaN        NaN  \n",
       "64374269     10260243.0        NaN        NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(DATA_PATH, \"results\", \"baseline_2_results.csv\")\n",
    "df_results = pd.read_csv(file_path, index_col=\"question_id\")\n",
    "df_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a586878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @20: 0.00019\n",
      "Recall @20: 0.0028666666666666662\n"
     ]
    }
   ],
   "source": [
    "R = df_results.values\n",
    "# order the actual answers base on the prediction\n",
    "df_actual = pd.DataFrame(df_answers.groupby(\"question_id\").user_id.apply(list))\n",
    "A = list(df_actual.loc[df_results.index].values[:, 0])\n",
    "\n",
    "print(f\"Precision @20: {precision_k(Y=A, Y_pred=R)}\")\n",
    "print(f\"Recall @20: {recall_k(Y=A, Y_pred=R)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cb1c7",
   "metadata": {},
   "source": [
    "Compare it to dummy prediction where we simply select the top 20 users with the most answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dbd9e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @20: 0.0032\n",
      "Recall @20: 0.0466\n"
     ]
    }
   ],
   "source": [
    "top_20_users = df_answers.user_id.value_counts().head(20)\n",
    "R_dummy = [top_20_users.index] * len(A)\n",
    "\n",
    "print(f\"Precision @20: {precision_k(Y=A, Y_pred=R_dummy):.4f}\")\n",
    "print(f\"Recall @20: {recall_k(Y=A, Y_pred=R_dummy):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f6b0b",
   "metadata": {},
   "source": [
    "We improved from the last baseline but we still performs poorly compared to the dummy prediction. Our embeddings might not be adapted for titles, since there are a lot of tech-specific words.\n",
    "\n",
    "What is more, a 768 embeddings size might be too much for small text like titles. We need to lower embedding sizes to a more reasonable one like 64.\n",
    "\n",
    "As a follow-up we can try another embedding method like word2vec, were we would create embeddings specific to our titles instead of our current generic ones from Huggingface BERT.\n",
    "\n",
    "An even simpler approach would be to create labels on questions by running TF-IDF, so that for a new question we would simply look for users having already answered questions with shared labels —like \"kubernetes\" or \"node.js\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
