{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3f669c",
   "metadata": {},
   "source": [
    "# IV. Baseline #3 \n",
    "\n",
    "**Embeddings**\n",
    "\n",
    "With BERT embeddings, we looked at understanding complex relationships between tokens and infer tech concepts, but it showed to perform quite poorly for our task. Here we take a simpler approach by simply computing the TF-IDF embedding of each title and performing cosine similarity search to find the top-n similar questions.\n",
    "\n",
    "**Model**\n",
    "\n",
    "Like before, we fetch the users having answered to this subset of neighbor questions and rank them using basic heuristics like their total ratings on the subset and their reputation.\n",
    "\n",
    "Pros of this model:\n",
    "- Embeddings are faster to compute and easier to understand\n",
    "- Embeddings are more specific to our tech-oriented text\n",
    "- Simple ranking heuristics can give sensible solutions\n",
    "\n",
    "Cons:\n",
    "- Brute-force cosine similarity is compute intensive\n",
    "- kNN is a decent approximation for lower dimensional vectors but can get quickly innacurate due to the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f36abf",
   "metadata": {},
   "source": [
    "## Load data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2fb20bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from src.data import load_data, split_questions, save_results_csv, DATA_PATH\n",
    "from src.embedder import stop_words\n",
    "from src.score import precision_k, recall_k\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1548d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_answers.shape: (95709, 6)\n",
      "df_questions.shape: (100000, 6)\n",
      "df_users.shape: (138698, 12)\n"
     ]
    }
   ],
   "source": [
    "df_answers, df_questions, df_users = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b008c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_train.shape: (65036, 8)\n",
      "Q_val.shape: (5000, 8)\n",
      "Q_test.shape: (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "Q_train, Q_val, Q_test = split_questions(df_questions, df_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83331146",
   "metadata": {},
   "source": [
    "Credits to [Ciprian Borodescu](https://www.algolia.com/blog/ai/the-anatomy-of-high-performance-recommender-systems-part-iv/) for this neat implementation of TF-IDF below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71b13dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query title: ['Return an array with all negatives in a matrix']\n",
      "most similar titles: ['Return an array after loop async'\n",
      " 'How can code return an array of characters in C?'\n",
      " 'How to return an array which is an element of an multidimensional array?'\n",
      " 'How to return array of urls in django'\n",
      " 'How do you return an array of structs from a function in C?'\n",
      " 'Why does it return 1?'\n",
      " 'Return Array of Objects in JSON in django rest_framework'\n",
      " 'Return an array of items that satisfies a specific rule'\n",
      " 'How can I return an array of all items in the provided array that include a singular item'\n",
      " 'Return array value from produce function | immer.js']\n"
     ]
    }
   ],
   "source": [
    "# creating the tf-idf Vectorizer to analyze, at word level, unigrams and bigrams\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), stop_words=stop_words) \n",
    " \n",
    "# applying the vectorizer on the 'title' column\n",
    "tfidf_matrix = tf.fit_transform(Q_train[\"title\"])\n",
    "\n",
    "# getting the embedding for a validation question\n",
    "query_title = [Q_val.iloc[0].title]\n",
    "tfidf_vector_query = tf.transform(query_title)\n",
    "\n",
    "# compute the cosine similarity between the training matrix and the query vector\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_vector_query)\n",
    "\n",
    "# return the top 10 closest titles (excluding the query)\n",
    "top_idxs = np.argsort(cosine_sim, axis=0)[::-1][1:11].ravel()\n",
    "print(\"query title:\", query_title)\n",
    "print(\"most similar titles:\", Q_train.iloc[top_idxs].title.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec8354",
   "metadata": {},
   "source": [
    "## Brute force cosine sim\n",
    "\n",
    "Let's compute the closest questions for our validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46827221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_questions(tf, tfidf_matrix, Q_val, Q_train, df_answers, df_users, n_top_questions=20):\n",
    "    \"\"\"\n",
    "    For a given question (or dataset of question), find top users by:\n",
    "    1. Computing the cosine sim between Q_train and Q_val titles\n",
    "    2. Fetching the 20 nearest neighbours for each questions\n",
    "    3. Choosing the top 20 users having the higher cumulative score on these neighbours questions,\n",
    "       break equality with users reputation.\n",
    "    \"\"\"\n",
    "    # embed and get similarity of our validation questions\n",
    "    tfidf_matrix_query = tf.transform(Q_val[\"title\"])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix_query)\n",
    "    \n",
    "    # get the n_top_questions closest training questions for each query\n",
    "    top_idxs_matrix = np.argsort(cosine_sim, axis=0)[::-1][1:n_top_questions+1].T\n",
    "    \n",
    "    # get the top users for each validation question\n",
    "    question_ids_val = Q_val.question_id.values\n",
    "    results = []\n",
    "    for question_id, top_idxs in tqdm(zip(question_ids_val, top_idxs_matrix), total=len(question_ids_val)):\n",
    "        neighbour_question_ids = Q_train.iloc[top_idxs].question_id.values\n",
    "        # apply rules to get our top user ids for this questions\n",
    "        top_user_ids = df_answers.loc[df_answers.question_id.isin(neighbour_question_ids)] \\\n",
    "                                  .groupby(\"user_id\").score.sum().reset_index() \\\n",
    "                                  .merge(df_users, left_on=\"user_id\", right_on=\"id\", how=\"inner\") \\\n",
    "                                  .sort_values([\"score\", \"reputation\"], ascending=[False, False]) \\\n",
    "                                  .head(20).user_id.values\n",
    "        results.append(np.hstack([question_id, top_user_ids]))\n",
    "    \n",
    "    # saving results to compute score\n",
    "    save_results_csv(\"baseline_3_results.csv\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4b0482a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e24f50a4f245ed874fc3d9d60cea76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/results/baseline_3_results.csv written\n"
     ]
    }
   ],
   "source": [
    "get_top_questions(tf, tfidf_matrix, Q_val, Q_train, df_answers, df_users, n_top_questions=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d808a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1_id</th>\n",
       "      <th>user2_id</th>\n",
       "      <th>user3_id</th>\n",
       "      <th>user4_id</th>\n",
       "      <th>user5_id</th>\n",
       "      <th>user6_id</th>\n",
       "      <th>user7_id</th>\n",
       "      <th>user8_id</th>\n",
       "      <th>user9_id</th>\n",
       "      <th>user10_id</th>\n",
       "      <th>user11_id</th>\n",
       "      <th>user12_id</th>\n",
       "      <th>user13_id</th>\n",
       "      <th>user14_id</th>\n",
       "      <th>user15_id</th>\n",
       "      <th>user16_id</th>\n",
       "      <th>user17_id</th>\n",
       "      <th>user18_id</th>\n",
       "      <th>user19_id</th>\n",
       "      <th>user20_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60698269</th>\n",
       "      <td>12158757</td>\n",
       "      <td>6574038</td>\n",
       "      <td>3732271</td>\n",
       "      <td>10429793</td>\n",
       "      <td>2586922</td>\n",
       "      <td>10248678</td>\n",
       "      <td>5030014</td>\n",
       "      <td>1447675</td>\n",
       "      <td>3293881</td>\n",
       "      <td>6243352</td>\n",
       "      <td>1411277</td>\n",
       "      <td>9901261</td>\n",
       "      <td>9661744</td>\n",
       "      <td>3962914</td>\n",
       "      <td>2877241</td>\n",
       "      <td>5459839</td>\n",
       "      <td>4620771</td>\n",
       "      <td>12500315</td>\n",
       "      <td>6110094</td>\n",
       "      <td>1822379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61476685</th>\n",
       "      <td>8583393</td>\n",
       "      <td>12299030</td>\n",
       "      <td>7687641</td>\n",
       "      <td>9698684</td>\n",
       "      <td>6950186</td>\n",
       "      <td>12299000</td>\n",
       "      <td>5238915</td>\n",
       "      <td>3732271</td>\n",
       "      <td>2372064</td>\n",
       "      <td>797495</td>\n",
       "      <td>10618540</td>\n",
       "      <td>2901002</td>\n",
       "      <td>7964527</td>\n",
       "      <td>6622587</td>\n",
       "      <td>1639625</td>\n",
       "      <td>3874623</td>\n",
       "      <td>10035985</td>\n",
       "      <td>4552295</td>\n",
       "      <td>10201580</td>\n",
       "      <td>10068985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59551270</th>\n",
       "      <td>2887218</td>\n",
       "      <td>7098650</td>\n",
       "      <td>7085197</td>\n",
       "      <td>1491895</td>\n",
       "      <td>1447675</td>\n",
       "      <td>11654</td>\n",
       "      <td>1100248</td>\n",
       "      <td>6950238</td>\n",
       "      <td>3867033</td>\n",
       "      <td>2035262</td>\n",
       "      <td>5249621</td>\n",
       "      <td>650475</td>\n",
       "      <td>159388</td>\n",
       "      <td>13552470</td>\n",
       "      <td>1225617</td>\n",
       "      <td>988260</td>\n",
       "      <td>8891224</td>\n",
       "      <td>4934937</td>\n",
       "      <td>5215131</td>\n",
       "      <td>6510523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user1_id  user2_id  user3_id  user4_id  user5_id  user6_id  \\\n",
       "question_id                                                               \n",
       "60698269     12158757   6574038   3732271  10429793   2586922  10248678   \n",
       "61476685      8583393  12299030   7687641   9698684   6950186  12299000   \n",
       "59551270      2887218   7098650   7085197   1491895   1447675     11654   \n",
       "\n",
       "             user7_id  user8_id  user9_id  user10_id  user11_id  user12_id  \\\n",
       "question_id                                                                  \n",
       "60698269      5030014   1447675   3293881    6243352    1411277    9901261   \n",
       "61476685      5238915   3732271   2372064     797495   10618540    2901002   \n",
       "59551270      1100248   6950238   3867033    2035262    5249621     650475   \n",
       "\n",
       "             user13_id  user14_id  user15_id  user16_id  user17_id  user18_id  \\\n",
       "question_id                                                                     \n",
       "60698269       9661744    3962914    2877241    5459839    4620771   12500315   \n",
       "61476685       7964527    6622587    1639625    3874623   10035985    4552295   \n",
       "59551270        159388   13552470    1225617     988260    8891224    4934937   \n",
       "\n",
       "             user19_id  user20_id  \n",
       "question_id                        \n",
       "60698269       6110094    1822379  \n",
       "61476685      10201580   10068985  \n",
       "59551270       5215131    6510523  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(DATA_PATH, \"results\", \"baseline_3_results.csv\")\n",
    "df_results = pd.read_csv(file_path, index_col=\"question_id\")\n",
    "df_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61f68af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @20: 0.0067\n",
      "Recall @20: 0.10945999999999999\n"
     ]
    }
   ],
   "source": [
    "R = df_results.values\n",
    "# order the actual answers base on the prediction\n",
    "df_actual = pd.DataFrame(df_answers.groupby(\"question_id\").user_id.apply(list))\n",
    "A = list(df_actual.loc[df_results.index].values[:, 0])\n",
    "\n",
    "print(f\"Precision @20: {precision_k(Y=A, Y_pred=R)}\")\n",
    "print(f\"Recall @20: {recall_k(Y=A, Y_pred=R)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb9513",
   "metadata": {},
   "source": [
    "Let's get the dummy recommender performance as a means of comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84446f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @20: 0.0031\n",
      "Recall @20: 0.0451\n"
     ]
    }
   ],
   "source": [
    "top_20_users = df_answers.user_id.value_counts().head(20)\n",
    "R_dummy = [top_20_users.index] * len(A)\n",
    "\n",
    "print(f\"Precision @20: {precision_k(Y=A, Y_pred=R_dummy):.4f}\")\n",
    "print(f\"Recall @20: {recall_k(Y=A, Y_pred=R_dummy):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e0154",
   "metadata": {},
   "source": [
    "At last, we finally beat the dummy recommender! What happen if we increase the `n_top_questions`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2066a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_top_questions):\n",
    "    \n",
    "    get_top_questions(tf, tfidf_matrix, Q_val, Q_train, df_answers, df_users, n_top_questions)\n",
    "    df_results = pd.read_csv(file_path, index_col=\"question_id\")\n",
    "\n",
    "    R = df_results.values\n",
    "    \n",
    "    # order the actual answers base on the prediction\n",
    "    df_actual = pd.DataFrame(df_answers.groupby(\"question_id\").user_id.apply(list))\n",
    "    A = list(df_actual.loc[df_results.index].values[:, 0])\n",
    "\n",
    "    print(f\"Precision @20: {precision_k(Y=A, Y_pred=R)}\")\n",
    "    print(f\"Recall @20: {recall_k(Y=A, Y_pred=R)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f7de65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d0ba8067b34b1996d4194b9105957e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/results/baseline_3_results.csv written\n",
      "Precision @20: 0.00704\n",
      "Recall @20: 0.11435333333333333\n"
     ]
    }
   ],
   "source": [
    "get_score(n_top_questions=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21e9e799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9914754dfdd4ab384978f1cd8592ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/results/baseline_3_results.csv written\n",
      "Precision @20: 0.006810000000000001\n",
      "Recall @20: 0.10883\n"
     ]
    }
   ],
   "source": [
    "get_score(n_top_questions=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5a84d",
   "metadata": {},
   "source": [
    "We are slightly better off with 50 top questions, but to get a stronger estimation we should run cross-validation on this parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5832cea",
   "metadata": {},
   "source": [
    "## kNN \n",
    "\n",
    "Finally, let's try to use a kNN model instead of brute-force cosine similarity to improve our speed and memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79e588f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_questions_knn(tf, knn, tfidf_matrix, Q_val, Q_train, df_answers, df_users, n_top_questions=20):\n",
    "    \"\"\"\n",
    "    For a given question (or dataset of question), find top users by:\n",
    "    1. Computing the kNN between Q_train and Q_val titles\n",
    "    2. Fetching the 20 nearest neighbours for each questions\n",
    "    3. Choosing the top 20 users having the higher cumulative score on these neighbours questions,\n",
    "       break equality with users reputation.\n",
    "    \"\"\"\n",
    "    # embed and get similarity of our validation questions\n",
    "    tfidf_matrix_query = tf.transform(Q_val[\"title\"])\n",
    "    \n",
    "    # get 20 closest neighbors matrix\n",
    "    top_idxs_matrix = knn.kneighbors(tfidf_matrix_query, return_distance=False)\n",
    "        \n",
    "    # get the top users for each validation question\n",
    "    question_ids_val = Q_val.question_id.values\n",
    "    results = []\n",
    "    for question_id, top_idxs in tqdm(zip(question_ids_val, top_idxs_matrix), total=len(question_ids_val)):\n",
    "        neighbour_question_ids = Q_train.iloc[top_idxs].question_id.values\n",
    "        # apply rules to get our top user ids for this questions\n",
    "        top_user_ids = df_answers.loc[df_answers.question_id.isin(neighbour_question_ids)] \\\n",
    "                                  .groupby(\"user_id\").score.sum().reset_index() \\\n",
    "                                  .merge(df_users, left_on=\"user_id\", right_on=\"id\", how=\"inner\") \\\n",
    "                                  .sort_values([\"score\", \"reputation\"], ascending=[False, False]) \\\n",
    "                                  .head(20).user_id.values\n",
    "        results.append(np.hstack([question_id, top_user_ids]))\n",
    "    \n",
    "    # saving results to compute score\n",
    "    save_results_csv(\"baseline_3_results.csv\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "042d4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_knn(n_top_questions):\n",
    "    \n",
    "    get_top_questions_knn(tf, knn, tfidf_matrix, Q_val, Q_train, df_answers, df_users, n_top_questions)\n",
    "    df_results = pd.read_csv(file_path, index_col=\"question_id\")\n",
    "\n",
    "    R = df_results.values\n",
    "    \n",
    "    # order the actual answers base on the prediction\n",
    "    df_actual = pd.DataFrame(df_answers.groupby(\"question_id\").user_id.apply(list))\n",
    "    A = list(df_actual.loc[df_results.index].values[:, 0])\n",
    "\n",
    "    print(f\"Precision @20: {precision_k(Y=A, Y_pred=R)}\")\n",
    "    print(f\"Recall @20: {recall_k(Y=A, Y_pred=R)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68e9bd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800e2fd87b1b493ca300fb5ab8b24205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/results/baseline_3_results.csv written\n",
      "Precision @20: 0.00468\n",
      "Recall @20: 0.07585\n"
     ]
    }
   ],
   "source": [
    "get_score_knn(n_top_questions=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3682acdb",
   "metadata": {},
   "source": [
    "Here we get a practical sense of tradeoff between the memory & compute efficiency vs metrics performance, our kNN is faster but both precision @20 and recall @20 are smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485c5f7",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "To improve those performances further, instead of simple heuristics we could try to build a classifier to suggest the higher probability for our user candidates to answer a question. We could then leverage more user attributes such as missing of photo, text (or labels) in their bio and number of replies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
