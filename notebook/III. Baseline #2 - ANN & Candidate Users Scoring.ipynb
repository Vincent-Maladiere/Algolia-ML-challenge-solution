{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f8cd76b",
   "metadata": {},
   "source": [
    "## III. Baseline #2: Nearest neighbours questions\n",
    "\n",
    "We apply the embeddings to questions title and feed them into a ANN model that will help us retrieve the nearest, say, 100 questions. With a simple ranking on users associated to those questions, we might obtain a decent baseline.\n",
    "\n",
    "We will use [Spotify ANNOY](https://github.com/spotify/annoy) model for fast indexing and retrieval of candidates questions. On benchmarks, ANNOY is faster than Facebook FAISS, and the high-dimensionality of our embeddings forbid us from using KDTree, prone to the curse of dimensionality.\n",
    "\n",
    "Pros of the model:\n",
    "- Simple to implement\n",
    "- Fast in production and adapted to batch, precompute inference settings\n",
    "- Intuitive results\n",
    "- Possibility to build a more complex ranking system afterwards\n",
    "\n",
    "Cons:\n",
    "- Two models instead of one\n",
    "- ANN is an Inductive model, we need to rebuild the indexing for each new entry, so it might not be ideal in a real-time setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4410869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "from src.data import load_data, split_questions, save_results_csv, DATA_PATH\n",
    "from src.embedder import BertEmbedder\n",
    "from src.score import precision_k, recall_k\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b01aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PRECOMPUTE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e11f0896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_answers.shape: (95709, 6)\n",
      "df_questions.shape: (100000, 6)\n",
      "df_users.shape: (138698, 12)\n"
     ]
    }
   ],
   "source": [
    "df_answers, df_questions, df_users = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ee268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_train.shape: (65036, 8)\n",
      "Q_val.shape: (5000, 8)\n",
      "Q_test.shape: (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "Q_train, Q_val, Q_test = split_questions(df_questions, df_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99451822",
   "metadata": {},
   "source": [
    "We begin by computing embeddings of both train and validation questions title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8234b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_questions_embeddings(df_questions, embedder, file_name):\n",
    "    results = []\n",
    "    for (question_id, title) in tqdm(df_questions[[\"question_id\", \"title\"]].values):\n",
    "        embeddings = embedder.get_embeddings(title)\n",
    "        results.append({\"question_id\": question_id, \"title\": title, \"embeddings\": embeddings})\n",
    "    file_path = os.path.join(DATA_PATH, file_name)\n",
    "    df_q_embeddings = pd.DataFrame(results)\n",
    "    df_q_embeddings.to_pickle(file_path)\n",
    "    print(f\"{file_name} written\")\n",
    "    return df_q_embeddings\n",
    "\n",
    "def load_questions_embeddings(file_name):\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    return pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3115b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedder = BertEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3889937e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaf86ead0c240c58b5f5c12f011a7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_embeddings.pkl written\n"
     ]
    }
   ],
   "source": [
    "file_name = \"q_embeddings.pkl\"\n",
    "if USE_PRECOMPUTE:\n",
    "    df_q_embeddings = load_questions_embeddings(file_name)\n",
    "else:\n",
    "    Q_train_val = pd.concat([Q_train, Q_val])\n",
    "    df_q_embeddings = compute_questions_embeddings(Q_train_val, embedder, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c070c7",
   "metadata": {},
   "source": [
    "Quick demo using the first question indexed (index 0), we query the 10 neareast questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a709d8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca02be1c3b64165a7254fe64eb9a4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = AnnoyIndex(768, \"angular\")\n",
    "embeddings = df_q_embeddings.embeddings.values\n",
    "for idx, v in tqdm(enumerate(embeddings), total=len(embeddings)):\n",
    "    ann.add_item(idx, v)\n",
    "ann.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd384c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>title</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>63142034</td>\n",
       "      <td>How to create an automation for tplink pharos ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>63051247</td>\n",
       "      <td>selenium cannot import name webdriver in ubuntu</td>\n",
       "      <td>0.337811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15578</th>\n",
       "      <td>63695568</td>\n",
       "      <td>Is there any embedded database for Node.js tha...</td>\n",
       "      <td>0.347284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32458</th>\n",
       "      <td>63849070</td>\n",
       "      <td>Authentication Exception when trying to connec...</td>\n",
       "      <td>0.367351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39417</th>\n",
       "      <td>61494103</td>\n",
       "      <td>Neovim plugin Fugitive isn't using the ssh key...</td>\n",
       "      <td>0.368468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52724</th>\n",
       "      <td>63230711</td>\n",
       "      <td>Configuration domain name on nginx on linux?</td>\n",
       "      <td>0.369126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54445</th>\n",
       "      <td>63841827</td>\n",
       "      <td>How do I use synology domain name for azure</td>\n",
       "      <td>0.371456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55446</th>\n",
       "      <td>60364031</td>\n",
       "      <td>git username visible to nginx</td>\n",
       "      <td>0.372364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84514</th>\n",
       "      <td>62677039</td>\n",
       "      <td>Displaying data from mySQL database to vue.js ...</td>\n",
       "      <td>0.372692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95698</th>\n",
       "      <td>60544448</td>\n",
       "      <td>selenium with firefox close tab by javascript ...</td>\n",
       "      <td>0.373452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id                                              title  \\\n",
       "2171      63142034  How to create an automation for tplink pharos ...   \n",
       "4682      63051247    selenium cannot import name webdriver in ubuntu   \n",
       "15578     63695568  Is there any embedded database for Node.js tha...   \n",
       "32458     63849070  Authentication Exception when trying to connec...   \n",
       "39417     61494103  Neovim plugin Fugitive isn't using the ssh key...   \n",
       "52724     63230711       Configuration domain name on nginx on linux?   \n",
       "54445     63841827        How do I use synology domain name for azure   \n",
       "55446     60364031                      git username visible to nginx   \n",
       "84514     62677039  Displaying data from mySQL database to vue.js ...   \n",
       "95698     60544448  selenium with firefox close tab by javascript ...   \n",
       "\n",
       "       distances  \n",
       "2171    0.000000  \n",
       "4682    0.337811  \n",
       "15578   0.347284  \n",
       "32458   0.367351  \n",
       "39417   0.368468  \n",
       "52724   0.369126  \n",
       "54445   0.371456  \n",
       "55446   0.372364  \n",
       "84514   0.372692  \n",
       "95698   0.373452  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs, distances = ann.get_nns_by_item(0, 10, include_distances=True)\n",
    "question_ids = df_q_embeddings.iloc[idxs].question_id\n",
    "df_results = df_questions.loc[df_questions.question_id.isin(question_ids)][[\"question_id\", \"title\"]]\n",
    "df_results[\"distances\"] = distances\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54bdbc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['How to create an automation for tplink pharos cpe520 using xpath with selenium and python for log in?',\n",
       "       'selenium cannot import name webdriver in ubuntu',\n",
       "       'Is there any embedded database for Node.js that allows to use mongoose driver API?',\n",
       "       'Authentication Exception when trying to connect to Amazon keyspace using .net core and cassandra csharp driver from linux',\n",
       "       \"Neovim plugin Fugitive isn't using the ssh key agent, so I can't Gpush/Git push\",\n",
       "       'Configuration domain name on nginx on linux?',\n",
       "       'How do I use synology domain name for azure',\n",
       "       'git username visible to nginx',\n",
       "       'Displaying data from mySQL database to vue.js front end using PHP',\n",
       "       'selenium with firefox close tab by javascript but SetTimeout() not ok'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.title.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c73e7",
   "metadata": {},
   "source": [
    "In the results above, we have returned the 9 closest titles to the first one (notice the increasing distances between the first row and the rest). There is room for improvement in those results: we find some similarity based on API, proxy and selenium but questions linked to ssh seems to be a bit far-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0d72b",
   "metadata": {},
   "source": [
    "We now define the dataset that our model will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6503ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset:\n",
    "    question_ids_to_predict: list[int]\n",
    "    embeddings: list\n",
    "    questions_idxs_mapping: pd.DataFrame\n",
    "    df_answers: pd.DataFrame\n",
    "    df_users: pd.DataFrame\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_ids_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff06276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(\n",
    "    question_ids_to_predict=Q_val.question_id.values,\n",
    "    embeddings=df_q_embeddings.embeddings.tolist(),\n",
    "    questions_idxs_mapping=Q_train_val,\n",
    "    df_answers=df_answers,\n",
    "    df_users=df_users,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70a55f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Ranker:    \n",
    "    \n",
    "    def predict_users(self, ds, n_top_users=20, k_nearest_questions=40):\n",
    "        self.ann = self.build_ann(ds)\n",
    "        results = []\n",
    "        print(\" # [ANN_Ranker] Make users predictions\")\n",
    "        for idx, question_id in enumerate(tqdm(ds.question_ids_to_predict, total=len(ds))):\n",
    "            question_ids = self.get_nearest_questions(idx, ds, k_nearest_questions)\n",
    "            top_user_ids = self.get_top_users(question_ids, ds, n_top=20)\n",
    "            results.append(np.hstack([question_id, top_user_ids]))\n",
    "        save_results_csv(\"baseline_2_results.csv\", results)\n",
    "    \n",
    "    def build_ann(self, ds, distance=\"angular\", size=768):\n",
    "        print(\" # [ANN_Ranker] Build ANN\")\n",
    "        ann = AnnoyIndex(size, distance)\n",
    "        for idx, v in tqdm(enumerate(ds.embeddings), total=len(ds.embeddings)):\n",
    "            ann.add_item(idx, v)\n",
    "        ann.build(10)\n",
    "        return ann\n",
    "\n",
    "    def get_nearest_questions(self, idx, ds, k_nearest_questions):\n",
    "        idxs = ann.get_nns_by_item(idx, k_nearest_questions)\n",
    "        idxs = np.array(idxs)\n",
    "        question_ids = ds.questions_idxs_mapping.iloc[idxs].question_id.values\n",
    "        return question_ids\n",
    "\n",
    "    def get_top_users(self, question_ids, ds, n_top=20):\n",
    "        df_answers_nn = ds.df_answers.loc[ds.df_answers.question_id.isin(question_ids)]\n",
    "        df_top_users = df_answers_nn.groupby(\"user_id\").score.sum().reset_index()\n",
    "        df_top_users = df_top_users.merge(\n",
    "            ds.df_users[[\"id\", \"reputation\"]], left_on=\"user_id\", right_on=\"id\", how=\"left\"\n",
    "        )\n",
    "        df_top_users.sort_values([\"score\", \"reputation\"], ascending=[False, False], inplace=True)\n",
    "        return df_top_users.user_id[:n_top].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67a07966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # [ANN_Ranker] Build ANN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b31c3894314b1a917e02d74d723de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # [ANN_Ranker] Make users predictions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6b038984404339bb0a18107a05f372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/results/baseline_2_results written\n"
     ]
    }
   ],
   "source": [
    "ann_ranker = ANN_Ranker()\n",
    "ann_ranker.predict_users(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b7593fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1_id</th>\n",
       "      <th>user2_id</th>\n",
       "      <th>user3_id</th>\n",
       "      <th>user4_id</th>\n",
       "      <th>user5_id</th>\n",
       "      <th>user6_id</th>\n",
       "      <th>user7_id</th>\n",
       "      <th>user8_id</th>\n",
       "      <th>user9_id</th>\n",
       "      <th>user10_id</th>\n",
       "      <th>user11_id</th>\n",
       "      <th>user12_id</th>\n",
       "      <th>user13_id</th>\n",
       "      <th>user14_id</th>\n",
       "      <th>user15_id</th>\n",
       "      <th>user16_id</th>\n",
       "      <th>user17_id</th>\n",
       "      <th>user18_id</th>\n",
       "      <th>user19_id</th>\n",
       "      <th>user20_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61821197</th>\n",
       "      <td>11329890</td>\n",
       "      <td>58456</td>\n",
       "      <td>6309</td>\n",
       "      <td>1658906</td>\n",
       "      <td>4399281</td>\n",
       "      <td>70465</td>\n",
       "      <td>6797509</td>\n",
       "      <td>8813644</td>\n",
       "      <td>7535379</td>\n",
       "      <td>14620948</td>\n",
       "      <td>12821415</td>\n",
       "      <td>209103</td>\n",
       "      <td>235648</td>\n",
       "      <td>10185816</td>\n",
       "      <td>5577076</td>\n",
       "      <td>1023597</td>\n",
       "      <td>11061080</td>\n",
       "      <td>2834065</td>\n",
       "      <td>7706936</td>\n",
       "      <td>10304821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60874696</th>\n",
       "      <td>1059372</td>\n",
       "      <td>1113486</td>\n",
       "      <td>6869836</td>\n",
       "      <td>4665755</td>\n",
       "      <td>440558</td>\n",
       "      <td>2877241</td>\n",
       "      <td>4238408</td>\n",
       "      <td>10008173</td>\n",
       "      <td>765226</td>\n",
       "      <td>9959152</td>\n",
       "      <td>5820814</td>\n",
       "      <td>8367626</td>\n",
       "      <td>9518890</td>\n",
       "      <td>5105949</td>\n",
       "      <td>11227781</td>\n",
       "      <td>5028841</td>\n",
       "      <td>6079412</td>\n",
       "      <td>10490683</td>\n",
       "      <td>6066528</td>\n",
       "      <td>470214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64374269</th>\n",
       "      <td>3732271</td>\n",
       "      <td>12323248</td>\n",
       "      <td>1144035</td>\n",
       "      <td>5089204</td>\n",
       "      <td>3385827</td>\n",
       "      <td>11897007</td>\n",
       "      <td>3219613</td>\n",
       "      <td>10959940</td>\n",
       "      <td>1548468</td>\n",
       "      <td>7299782</td>\n",
       "      <td>13808319</td>\n",
       "      <td>10305477</td>\n",
       "      <td>6635033</td>\n",
       "      <td>3825777</td>\n",
       "      <td>4785185</td>\n",
       "      <td>4117728</td>\n",
       "      <td>568283</td>\n",
       "      <td>132438</td>\n",
       "      <td>8198946</td>\n",
       "      <td>8805315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user1_id  user2_id  user3_id  user4_id  user5_id  user6_id  \\\n",
       "question_id                                                               \n",
       "61821197     11329890     58456      6309   1658906   4399281     70465   \n",
       "60874696      1059372   1113486   6869836   4665755    440558   2877241   \n",
       "64374269      3732271  12323248   1144035   5089204   3385827  11897007   \n",
       "\n",
       "             user7_id  user8_id  user9_id  user10_id  user11_id  user12_id  \\\n",
       "question_id                                                                  \n",
       "61821197      6797509   8813644   7535379   14620948   12821415     209103   \n",
       "60874696      4238408  10008173    765226    9959152    5820814    8367626   \n",
       "64374269      3219613  10959940   1548468    7299782   13808319   10305477   \n",
       "\n",
       "             user13_id  user14_id  user15_id  user16_id  user17_id  user18_id  \\\n",
       "question_id                                                                     \n",
       "61821197        235648   10185816    5577076    1023597   11061080    2834065   \n",
       "60874696       9518890    5105949   11227781    5028841    6079412   10490683   \n",
       "64374269       6635033    3825777    4785185    4117728     568283     132438   \n",
       "\n",
       "             user19_id  user20_id  \n",
       "question_id                        \n",
       "61821197       7706936   10304821  \n",
       "60874696       6066528     470214  \n",
       "64374269       8198946    8805315  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(DATA_PATH, \"results\", \"baseline_2_results\")\n",
    "df_results = pd.read_csv(file_path, index_col=\"question_id\")\n",
    "df_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a586878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @20: 0.0005300000000000001\n",
      "Recall @20: 0.007945238095238095\n"
     ]
    }
   ],
   "source": [
    "R = df_results.values\n",
    "# order the actual answers base on the prediction\n",
    "df_actual = pd.DataFrame(df_answers.groupby(\"question_id\").user_id.apply(list))\n",
    "A = list(df_actual.loc[df_results.index].values[:, 0])\n",
    "\n",
    "print(f\"Precision @20: {precision_k(Y=A, Y_pred=R)}\")\n",
    "print(f\"Recall @20: {recall_k(Y=A, Y_pred=R)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cb1c7",
   "metadata": {},
   "source": [
    "Compare it to dummy prediction where we simply select the top 20 users with the most answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4dbd9e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @20: 0.0032\n",
      "Recall @20: 0.0466\n"
     ]
    }
   ],
   "source": [
    "top_20_users = df_answers.user_id.value_counts().head(20)\n",
    "R_dummy = [top_20_users.index] * len(A)\n",
    "\n",
    "print(f\"Precision @20: {precision_k(Y=A, Y_pred=R_dummy):.4f}\")\n",
    "print(f\"Recall @20: {recall_k(Y=A, Y_pred=R_dummy):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f6b0b",
   "metadata": {},
   "source": [
    "We improved from the last baseline but we still performs poorly compared to the dummy prediction. Our embeddings might not be adapted for titles, since there are a lot of tech-specific words.\n",
    "\n",
    "What is more, a 768 embeddings size might be too much for small text like titles. We need to lower embedding sizes to a more reasonable one like 64.\n",
    "\n",
    "As a follow-up we can try another embedding method like word2vec, were we would create embeddings specific to our titles instead of our current generic ones from Huggingface BERT.\n",
    "\n",
    "An even simpler approach would be to create labels on questions by running TF-IDF, so that for a new question we would simply look for users having already answered questions with shared labels —like \"kubernetes\" or \"node.js\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
